{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Module\n",
    "\n",
    "Now that we have our cleaned dataset, we can finally start training our models to predict real estate price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing important libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "# Import specified linear algorithms\n",
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "\n",
    "# Import specified ensemble algorithms \n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5330, 34)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('training_data.csv')\n",
    "df = df.drop(columns=['хаяг'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object for our target variable\n",
    "\n",
    "y = df['үнэ']\n",
    "\n",
    "# seperate object for our input features\n",
    "\n",
    "X = df.drop('үнэ', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4264, 1066, 4264, 1066)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# verify length of each set\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lasso' : make_pipeline(StandardScaler(), Lasso(random_state=123)),\n",
    "    'ridge' : make_pipeline(StandardScaler(), Ridge(random_state=123)),\n",
    "    'enet' : make_pipeline(StandardScaler(), ElasticNet(random_state=123)),\n",
    "    'rf' : make_pipeline(StandardScaler(), RandomForestRegressor(random_state=123)),\n",
    "    'gb' : make_pipeline(StandardScaler(), GradientBoostingRegressor(random_state=123))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  0.7610697757545168\n",
      "Test Accuracy     =  0.7466088275296585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear = LinearRegression()\n",
    "linear.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy = \", linear.score(X_train, y_train))\n",
    "print(\"Test Accuracy     = \", linear.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  1.0\n",
      "Test Accuracy     =  0.7551054011550429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(min_samples_split=2)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy = \", dt.score(X_train, y_train))\n",
    "print(\"Test Accuracy     = \", dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  0.8361042638903161\n",
      "Test Accuracy     =  0.8058338493907393\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 1000, max_depth=5, random_state = 12)\n",
    "rf.fit(X_train, y_train);\n",
    "\n",
    "print(\"Training Accuracy = \", rf.score(X_train, y_train))\n",
    "print(\"Test Accuracy     = \", rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  0.8523215311322855\n",
      "Test Accuracy     =  0.8225036517570986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "poly.fit_transform(X)\n",
    "\n",
    "# Define the pipeline and train model\n",
    "poly_model = Pipeline([('poly', PolynomialFeatures(degree=2)),\n",
    "                       ('rf', RandomForestRegressor(n_estimators = 1000, max_depth=5, random_state = 12))])\n",
    "poly_model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the Score\n",
    "print(\"Training Accuracy = \", poly_model.score(X_train, y_train))\n",
    "print(\"Test Accuracy     = \", poly_model.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
